{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141bd811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime, timezone\n",
    "import ipaddress\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score as sil_,\n",
    "    silhouette_samples,\n",
    "    calinski_harabasz_score as calinski_,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e77e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:16<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def load_data(directory):\n",
    "    data = []\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(directory, file))\n",
    "            data.append(df)\n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "df = load_data('data/cic')\n",
    "# Clean column names (in case of whitespace)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df[df['Label'] != 'BENIGN']\n",
    "\n",
    "features = df.select_dtypes(include=[np.number]).copy()\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features.dropna(inplace=True)\n",
    "df = df.loc[features.index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac57757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d6d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_attack_label(label):\n",
    "    if label == \"BENIGN\":\n",
    "        return \"Benign\"\n",
    "    elif \"DoS\" in label or label == \"DDoS\":\n",
    "        return \"DoS/DDoS\"\n",
    "    elif \"PortScan\" in label:\n",
    "        return \"Scan\"\n",
    "    elif \"Patator\" in label:\n",
    "        return \"BruteForce\"\n",
    "    elif \"Web Attack\" in label:\n",
    "        return \"WebAttack\"\n",
    "    elif label in [\"Bot\", \"Infiltration\", \"Heartbleed\"]:\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df['label_group'] = df['Label'].apply(group_attack_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f8b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('bwd', case=False)]\n",
    "df = df.loc[:, ~df.columns.str.contains('backward', case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1f697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/grouped_df.pkl', 'rb') as f:\n",
    "    grouped_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec51ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cic_columns = grouped_df.filter(regex='^cic').columns\n",
    "grouped_df = grouped_df[[col for col in grouped_df.columns if 'emb' not in col]]\n",
    "grouped_df_cic = grouped_df[cic_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0481d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucch\\AppData\\Local\\Temp\\ipykernel_16256\\2453699586.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grouped_df_cic.rename(columns=rename_dict, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "feature_mapping = [\n",
    "    ('Destination Port', 'cic_Destination Port'),\n",
    "    ('Flow Duration', 'cic_Flow Duration'),\n",
    "    ('Total Fwd Packets', 'cic_Total Fwd Packets'),\n",
    "    ('Total Length of Fwd Packets', 'cic_Total Length of Fwd Packets'),\n",
    "    ('Fwd Packet Length Max', 'cic_Fwd Packet Length Max'),\n",
    "    ('Fwd Packet Length Min', 'cic_Fwd Packet Length Min'),\n",
    "    ('Fwd Packet Length Mean', 'cic_Fwd Packet Length Mean'),\n",
    "    ('Fwd Packet Length Std', 'cic_Fwd Packet Length Std'),\n",
    "    ('Flow Bytes/s', 'cic_Flow Bytes/s'),\n",
    "    ('Flow Packets/s', 'cic_Flow Packets/s'),\n",
    "    ('Flow IAT Mean', 'cic_Flow IAT Mean'),\n",
    "    ('Flow IAT Std', 'cic_Flow IAT Std'),\n",
    "    ('Flow IAT Max', 'cic_Flow IAT Max'),\n",
    "    ('Flow IAT Min', 'cic_Flow IAT Min'),\n",
    "    ('Fwd IAT Total', 'cic_Fwd IAT Total'),\n",
    "    ('Fwd IAT Mean', 'cic_Fwd IAT Mean'),\n",
    "    ('Fwd IAT Std', 'cic_Fwd IAT Std'),\n",
    "    ('Fwd IAT Max', 'cic_Fwd IAT Max'),\n",
    "    ('Fwd IAT Min', 'cic_Fwd IAT Min'),\n",
    "    ('Fwd Packets/s', 'cic_Fwd Packets/s'),\n",
    "    ('Min Packet Length', 'cic_Min Packet Length'),\n",
    "    ('Max Packet Length', 'cic_Max Packet Length'),\n",
    "    ('Packet Length Mean', 'cic_Packet Length Mean'),\n",
    "    ('Packet Length Std', 'cic_Packet Length Std'),\n",
    "    ('Packet Length Variance', 'cic_Packet Length Variance'),\n",
    "    ('Average Packet Size', 'cic_Average Packet Size'),\n",
    "    ('Avg Fwd Segment Size', 'cic_Avg Fwd Segment Size')\n",
    "]\n",
    "\n",
    "rename_dict = {cic_name: new_name for new_name, cic_name in feature_mapping}\n",
    "grouped_df_cic.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9273800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(grouped_df_cic.columns)\n",
    "columns.append(\"label_group\")\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f2f8a",
   "metadata": {},
   "source": [
    "# prepare the data \n",
    "- x_train x_test ect\n",
    "- the omni dataset to make predictions on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acdca8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BruteForce: 0\n",
      "DoS/DDoS: 1\n",
      "Other: 2\n",
      "Scan: 3\n",
      "WebAttack: 4\n",
      "\n",
      "Unique encoded values: [1 3 2 4 0]\n",
      "Original labels: ['DoS/DDoS' 'Scan' 'Other' 'WebAttack' 'BruteForce']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df['label_group_encoded'] = le.fit_transform(df['label_group'])\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"{label}: {i}\")\n",
    "print(\"\\nUnique encoded values:\", df['label_group_encoded'].unique())\n",
    "print(\"Original labels:\", df['label_group'].unique())\n",
    "df.drop(columns=[\"label_group\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c172030",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"label_group_encoded\"])\n",
    "y = df[\"label_group_encoded\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n",
    "x_grouped = grouped_df_cic.copy()\n",
    "\n",
    "scaler = QuantileTransformer()\n",
    "scaler.fit(x_train)\n",
    "x_train_df = pd.DataFrame(scaler.transform(x_train), columns=x.columns)\n",
    "x_test_df = pd.DataFrame(scaler.transform(x_test), columns=x.columns)\n",
    "x_grouped = pd.DataFrame(scaler.transform(x_grouped), columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_df.to_numpy().reshape(-1, 26, 1)\n",
    "x_test = x_test_df.to_numpy().reshape(-1, 26, 1)\n",
    "x_grouped_np = x_grouped.to_numpy().reshape(-1, 26, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c346c74",
   "metadata": {},
   "source": [
    "## Transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c90e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D\n",
    "from keras_nlp.layers import TransformerEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,762</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,762\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m165\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,047</span> (86.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,047\u001b[0m (86.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,047</span> (86.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,047\u001b[0m (86.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = Input(shape=(26, 1))\n",
    "\n",
    "x = Dense(32)(inputs) \n",
    "x = TransformerEncoder(\n",
    "    num_heads=6,\n",
    "    intermediate_dim=256,\n",
    "    dropout=0.2\n",
    ")(x)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(32)(x) \n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0a3a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6957/6957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 14ms/step - accuracy: 0.9402 - loss: 0.1872 - val_accuracy: 0.9801 - val_loss: 0.0741\n",
      "Epoch 2/10\n",
      "\u001b[1m6665/6957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9727 - loss: 0.0838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucch\\Desktop\\thesis-datasec\\thesis\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test ,y_test), batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55046e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict(x_test)\n",
    "pred = pred_probs.argmax(axis=1)\n",
    "\n",
    "omni_probs = model.predict(x_grouped_np)\n",
    "omni_pred = omni_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfba7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(omni_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776640bd",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a410f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f984556",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_test_df)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of CIC Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b75660",
   "metadata": {},
   "source": [
    "## umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=5)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_test_df)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of CIC data Colored by true labels')\n",
    "plt.colorbar(scatter, label='True labels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e21559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "background = x_train.iloc[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "\n",
    "explainer = shap.Explainer(model, background)\n",
    "shap_values = explainer(x_test[:200])\n",
    "feature_names = x.columns\n",
    "shap.summary_plot(shap_values, x_test[:200], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c23d7",
   "metadata": {},
   "source": [
    "# here I want to make an analysis of the predictions based on the features especially teh commands that where extracted in the omni document\n",
    "\n",
    "check if the predicted scan or ddos or other have commands that are expected os such attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb884b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = grouped_df.copy()\n",
    "df_analysis['predicted_label'] = omni_pred\n",
    "cmd_cols = [col for col in df_analysis.columns if col.startswith('cmd_')]\n",
    "\n",
    "# Get proportions per class\n",
    "binary_feature_means = df_analysis.groupby('predicted_label')[cmd_cols].mean() *100\n",
    "\n",
    "label_map = {\n",
    "    0: 'BruteForce',\n",
    "    1: 'DoS/DDoS',\n",
    "    2: 'Other',\n",
    "    3: 'Scan',\n",
    "    4: 'WebAttack'\n",
    "}\n",
    "\n",
    "binary_feature_means = binary_feature_means.rename(index=label_map)\n",
    "\n",
    "print(binary_feature_means.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(binary_feature_means, annot=True, cmap=\"Reds\", fmt=\".1f\")\n",
    "plt.title(\"Command Feature Usage (% of samples per predicted class)\")\n",
    "plt.xlabel(\"Command\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a36b9",
   "metadata": {},
   "source": [
    "# Model with high confidence predictions\n",
    "\n",
    "combined the data from the previous model and the very high confidence predictions of the moni data (>0.97) to then retrain and see if there is an improvement in the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de74c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.95\n",
    "\n",
    "high_conf_samples = []\n",
    "high_conf_labels = []\n",
    "\n",
    "for class_idx in range(omni_probs.shape[1]):\n",
    "    class_mask = (omni_pred == class_idx) & (omni_probs[:, class_idx] >= confidence_threshold)\n",
    "    selected = x_grouped[class_mask]\n",
    "    high_conf_samples.append(selected)\n",
    "    high_conf_labels.extend([class_idx] * selected.shape[0])\n",
    "\n",
    "if high_conf_samples:\n",
    "    x_high_conf = pd.concat(high_conf_samples, axis=0)\n",
    "    y_high_conf = np.array(high_conf_labels)\n",
    "else:\n",
    "    x_high_conf = pd.DataFrame()\n",
    "    y_high_conf = np.array([])\n",
    "\n",
    "print(f\"Selected {len(y_high_conf)} high-confidence samples.\")\n",
    "\n",
    "x_high_conf_train, x_test_aug, y_high_conf_train, y_test_aug = train_test_split(\n",
    "    x_high_conf,\n",
    "    y_high_conf,\n",
    "    test_size=0.3,\n",
    "    stratify=y_high_conf\n",
    ")\n",
    "\n",
    "x_train_aug = pd.concat([x_train_df, x_high_conf_train], axis=0)\n",
    "y_train_aug = np.concatenate([y_train, y_high_conf_train], axis=0)\n",
    "\n",
    "print(f\"Training set size after augmentation: {len(x_train_aug)}, eval set size: {len(x_test_aug)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49167341",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(26, 1))\n",
    "\n",
    "x = Dense(32)(inputs) \n",
    "x = TransformerEncoder(\n",
    "    num_heads=6,\n",
    "    intermediate_dim=256,\n",
    "    dropout=0.2\n",
    ")(x)\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dense(32)(x) \n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_aug, y_train_aug, validation_data=(x_test ,y_test), batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict(x_test)\n",
    "pred = pred_probs.argmax(axis=1)\n",
    "\n",
    "augmented = model.predict(x_test_aug)\n",
    "augmented_pred = augmented.argmax(axis=1)\n",
    "\n",
    "omni_probs = model.predict(x_grouped)\n",
    "omni_pred = omni_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5629f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11254911",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_aug, augmented_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_aug, augmented_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2663dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(omni_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10cb76",
   "metadata": {},
   "source": [
    "## PCA aumgented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of CIC Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e18bf1",
   "metadata": {},
   "source": [
    "## UMAP augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a633835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be567a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of cic data Colored by true labels')\n",
    "plt.colorbar(scatter, label='True labels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "background = x_train.iloc[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "\n",
    "explainer = shap.Explainer(model, background)\n",
    "shap_values = explainer(x_test[:200])\n",
    "\n",
    "shap.summary_plot(shap_values, x_test[:200], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = grouped_df.copy()\n",
    "df_analysis['predicted_label'] = omni_pred\n",
    "cmd_cols = [col for col in df_analysis.columns if col.startswith('cmd_')]\n",
    "\n",
    "# Get proportions per class\n",
    "binary_feature_means = df_analysis.groupby('predicted_label')[cmd_cols].mean() *100\n",
    "\n",
    "label_map = {\n",
    "    0: 'BruteForce',\n",
    "    1: 'DoS/DDoS',\n",
    "    2: 'Other',\n",
    "    3: 'Scan',\n",
    "    4: 'WebAttack'\n",
    "}\n",
    "\n",
    "binary_feature_means = binary_feature_means.rename(index=label_map)\n",
    "\n",
    "print(binary_feature_means.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654deb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(binary_feature_means, annot=True, cmap=\"Reds\", fmt=\".1f\")\n",
    "plt.title(\"Command Feature Usage (% of samples per predicted class)\")\n",
    "plt.xlabel(\"Command\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
