{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime, timezone\n",
    "import ipaddress\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score as sil_,\n",
    "    silhouette_samples,\n",
    "    calinski_harabasz_score as calinski_,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e03bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_data(directory):\n",
    "    data = []\n",
    "    for file in tqdm(os.listdir(directory)):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(directory, file))\n",
    "            data.append(df)\n",
    "    return pd.concat(data, ignore_index=True)\n",
    "\n",
    "df = load_data('data/cic')\n",
    "# Clean column names (in case of whitespace)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df[df['Label'] != 'BENIGN']\n",
    "\n",
    "features = df.select_dtypes(include=[np.number]).copy()\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features.dropna(inplace=True)\n",
    "df = df.loc[features.index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0be008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6aa4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_attack_label(label):\n",
    "    if label == \"BENIGN\":\n",
    "        return \"Benign\"\n",
    "    elif \"DoS\" in label or label == \"DDoS\":\n",
    "        return \"DoS/DDoS\"\n",
    "    elif \"PortScan\" in label:\n",
    "        return \"Scan\"\n",
    "    elif \"Patator\" in label:\n",
    "        return \"BruteForce\"\n",
    "    elif \"Web Attack\" in label:\n",
    "        return \"WebAttack\"\n",
    "    elif label in [\"Bot\", \"Infiltration\", \"Heartbleed\"]:\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df['label_group'] = df['Label'].apply(group_attack_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2541223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('bwd', case=False)]\n",
    "df = df.loc[:, ~df.columns.str.contains('backward', case=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/grouped_df.pkl', 'rb') as f:\n",
    "    grouped_df = pickle.load(f)\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ca6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cic_columns = grouped_df.filter(regex='^cic').columns\n",
    "grouped_df = grouped_df[[col for col in grouped_df.columns if 'emb' not in col]]\n",
    "grouped_df_cic = grouped_df[cic_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c99e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is called 'grouped_df'\n",
    "# Assuming your mapping list is called 'feature_mapping'\n",
    "\n",
    "feature_mapping = [\n",
    "    ('Destination Port', 'cic_Destination Port'),\n",
    "    ('Flow Duration', 'cic_Flow Duration'),\n",
    "    ('Total Fwd Packets', 'cic_Total Fwd Packets'),\n",
    "    ('Total Length of Fwd Packets', 'cic_Total Length of Fwd Packets'),\n",
    "    ('Fwd Packet Length Max', 'cic_Fwd Packet Length Max'),\n",
    "    ('Fwd Packet Length Min', 'cic_Fwd Packet Length Min'),\n",
    "    ('Fwd Packet Length Mean', 'cic_Fwd Packet Length Mean'),\n",
    "    ('Fwd Packet Length Std', 'cic_Fwd Packet Length Std'),\n",
    "    ('Flow Bytes/s', 'cic_Flow Bytes/s'),\n",
    "    ('Flow Packets/s', 'cic_Flow Packets/s'),\n",
    "    ('Flow IAT Mean', 'cic_Flow IAT Mean'),\n",
    "    ('Flow IAT Std', 'cic_Flow IAT Std'),\n",
    "    ('Flow IAT Max', 'cic_Flow IAT Max'),\n",
    "    ('Flow IAT Min', 'cic_Flow IAT Min'),\n",
    "    ('Fwd IAT Total', 'cic_Fwd IAT Total'),\n",
    "    ('Fwd IAT Mean', 'cic_Fwd IAT Mean'),\n",
    "    ('Fwd IAT Std', 'cic_Fwd IAT Std'),\n",
    "    ('Fwd IAT Max', 'cic_Fwd IAT Max'),\n",
    "    ('Fwd IAT Min', 'cic_Fwd IAT Min'),\n",
    "    ('Fwd Packets/s', 'cic_Fwd Packets/s'),\n",
    "    ('Min Packet Length', 'cic_Min Packet Length'),\n",
    "    ('Max Packet Length', 'cic_Max Packet Length'),\n",
    "    ('Packet Length Mean', 'cic_Packet Length Mean'),\n",
    "    ('Packet Length Std', 'cic_Packet Length Std'),\n",
    "    ('Packet Length Variance', 'cic_Packet Length Variance'),\n",
    "    ('Average Packet Size', 'cic_Average Packet Size'),\n",
    "    ('Avg Fwd Segment Size', 'cic_Avg Fwd Segment Size')\n",
    "]\n",
    "\n",
    "rename_dict = {cic_name: new_name for new_name, cic_name in feature_mapping}\n",
    "grouped_df_cic.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(grouped_df_cic.columns)\n",
    "columns.append(\"label_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91efec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = grouped_df_cic.select_dtypes(include='number').columns\n",
    "n_features = len(features)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(5 * n_cols, 4 * n_rows))\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    plt.hist(df[feature], bins=10, alpha=0.5, label='Original', color='blue', density=True)\n",
    "    plt.hist(grouped_df_cic[feature], bins=10, alpha=0.5, label='Grouped', color='orange', density=True)\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_cic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e7850",
   "metadata": {},
   "source": [
    "# prepare the data \n",
    "- x_train x_test ect\n",
    "- the omni dataset to make predictions on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb775bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df['label_group_encoded'] = le.fit_transform(df['label_group'])\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f\"{label}: {i}\")\n",
    "print(\"\\nUnique encoded values:\", df['label_group_encoded'].unique())\n",
    "print(\"Original labels:\", df['label_group'].unique())\n",
    "df.drop(columns=[\"label_group\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd082ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"label_group_encoded\"])\n",
    "y = df[\"label_group_encoded\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n",
    "x_grouped = grouped_df_cic.copy()\n",
    "\n",
    "scaler = QuantileTransformer()\n",
    "scaler.fit(x_train)\n",
    "x_train = pd.DataFrame(scaler.transform(x_train), columns=x.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x.columns)\n",
    "x_grouped = pd.DataFrame(scaler.transform(x_grouped), columns=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054af6c",
   "metadata": {},
   "source": [
    "# random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b068e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\")\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(x_test)\n",
    "omni_pred = rf.predict(x_grouped)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(omni_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_names = x.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feat_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feat_imp = feat_imp.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feat_imp['Feature'], feat_imp['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057b7cd",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Add\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, x_val, y_val):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred_probs = self.model.predict(self.x_val)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        f1 = f1_score(self.y_val, y_pred, average='macro')  # or 'weighted'\n",
    "        print(f\"\\nEpoch {epoch+1}: F1 Score = {f1:.4f}\")\n",
    "\n",
    "\n",
    "inp = Input(shape=(x_train.shape[1],))\n",
    "x1 = Dense(256)(inp)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = tf.keras.activations.relu(x1)\n",
    "\n",
    "x2 = Dense(128)(x1)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = tf.keras.activations.relu(x2)\n",
    "\n",
    "encoded = Dense(32)(x2)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "encoded = tf.keras.activations.relu(encoded)\n",
    "\n",
    "# Decoder\n",
    "d1 = Dense(128)(encoded)\n",
    "d1 = BatchNormalization()(d1)\n",
    "d1 = tf.keras.activations.relu(d1)\n",
    "\n",
    "d2 = Dense(256)(d1)\n",
    "d2 = BatchNormalization()(d2)\n",
    "d2 = tf.keras.activations.relu(d2)\n",
    "\n",
    "decoded = Dense(x_train.shape[1])(d2)\n",
    "\n",
    "residual_output = Add()([decoded, inp])\n",
    "\n",
    "output = Dense(5, activation='softmax')(residual_output)\n",
    "\n",
    "model = Model(inputs=inp, outputs=output)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_callback = F1ScoreCallback(x_val=x_test, y_val=y_test)\n",
    "cp = ModelCheckpoint(\n",
    "    \"best_model.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test), callbacks=[f1_callback, cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61447ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict(x_test)\n",
    "pred = pred_probs.argmax(axis=1)\n",
    "\n",
    "omni_probs = model.predict(x_grouped)\n",
    "omni_pred = omni_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26b413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(omni_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c1fce",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc5ad6",
   "metadata": {},
   "source": [
    "## umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc9d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of cic data Colored by true labels')\n",
    "plt.colorbar(scatter, label='True labels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "background = x_train.iloc[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "\n",
    "explainer = shap.Explainer(model, background)\n",
    "shap_values = explainer(x_test[:200])\n",
    "\n",
    "shap.summary_plot(shap_values, x_test[:200], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importances = np.array(rf.feature_importances_).flatten()\n",
    "shap_vals = shap_values.values  \n",
    "shap_importance = np.abs(shap_vals).mean(axis=0).mean(axis=1)\n",
    "\n",
    "assert len(rf_importances) == len(shap_importance) == x_train.shape[1]\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "compare_df = pd.DataFrame({\n",
    "    'Feature': x_train.columns,\n",
    "    'Random Forest Importance': rf_importances,\n",
    "    'SHAP Importance': shap_importance\n",
    "}).set_index('Feature')\n",
    "\n",
    "# Sort and plot\n",
    "compare_df = compare_df.sort_values('SHAP Importance', ascending=True)\n",
    "\n",
    "compare_df.plot(kind='barh', figsize=(10, 8))\n",
    "plt.title('Feature Importances: Random Forest vs SHAP (NN)')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d57f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_vals = silhouette_samples(x_grouped, omni_pred)\n",
    "avg_silhouette = sil_(x_grouped, omni_pred)\n",
    "\n",
    "# Sort for better visualization\n",
    "sorted_idx = np.argsort(omni_pred)\n",
    "sorted_silhouette_vals = silhouette_vals[sorted_idx]\n",
    "sorted_cluster_labels = omni_pred[sorted_idx]\n",
    "\n",
    "# Create silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_lower = 10\n",
    "unique_labels = np.unique(omni_pred)\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_sil_vals = sorted_silhouette_vals[sorted_cluster_labels == label]\n",
    "    label_sil_vals.sort()\n",
    "    y_upper = y_lower + len(label_sil_vals)\n",
    "\n",
    "    color = plt.cm.viridis(float(label) / (len(unique_labels) - 1))\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, label_sil_vals, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    ax.text(-0.05, y_lower + 0.5 * len(label_sil_vals), f'Cluster {label}')\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "# Draw average silhouette score line\n",
    "ax.axvline(avg_silhouette, color=\"red\", linestyle=\"--\", label=f\"Avg Silhouette = {avg_silhouette:.2f}\")\n",
    "ax.set_title(\"Silhouette Plot for HDBSCAN Clusters (Excluding Noise)\")\n",
    "ax.set_xlabel(\"Silhouette Coefficient Values\")\n",
    "ax.set_ylabel(\"Cluster Label\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a3360",
   "metadata": {},
   "source": [
    "# here I want to make an analysis of the predictions based on the features especially teh commands that where extracted in the omni document\n",
    "\n",
    "check if the predicted scan or ddos or other have commands that are expected os such attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53282255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = grouped_df.copy()\n",
    "df_analysis['predicted_label'] = omni_pred\n",
    "cmd_cols = [col for col in df_analysis.columns if col.startswith('cmd_')]\n",
    "\n",
    "# Get proportions per class\n",
    "binary_feature_means = df_analysis.groupby('predicted_label')[cmd_cols].mean() *100\n",
    "\n",
    "label_map = {\n",
    "    0: 'BruteForce',\n",
    "    1: 'DoS/DDoS',\n",
    "    2: 'Other',\n",
    "    3: 'Scan',\n",
    "    4: 'WebAttack'\n",
    "}\n",
    "\n",
    "binary_feature_means = binary_feature_means.rename(index=label_map)\n",
    "\n",
    "print(binary_feature_means.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(binary_feature_means, annot=True, cmap=\"Reds\", fmt=\".1f\")\n",
    "plt.title(\"Command Feature Usage (% of samples per predicted class)\")\n",
    "plt.xlabel(\"Command\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in binary_feature_means.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x=binary_feature_means.index, y=binary_feature_means[feature])\n",
    "    plt.title(f\"Usage of {feature} by Predicted Label\")\n",
    "    plt.ylabel(\"Percentage of Samples (%)\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c24f22",
   "metadata": {},
   "source": [
    "# Model with high confidence predictions\n",
    "\n",
    "combined the data from the previous model and the very high confidence predictions of the moni data (>0.97) to then retrain and see if there is an improvement in the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5fa173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set a confidence threshold (e.g., 0.95)\n",
    "confidence_threshold = 0.97\n",
    "\n",
    "# 2. For each class, select high-confidence samples\n",
    "high_conf_samples = []\n",
    "high_conf_labels = []\n",
    "\n",
    "for class_idx in range(omni_probs.shape[1]):\n",
    "    # Find indices where predicted class == class_idx and confidence is high\n",
    "    class_mask = (omni_pred == class_idx) & (omni_probs[:, class_idx] >= confidence_threshold)\n",
    "    selected = x_grouped[class_mask]\n",
    "    high_conf_samples.append(selected)\n",
    "    high_conf_labels.extend([class_idx] * selected.shape[0])\n",
    "\n",
    "# 3. Concatenate all high-confidence samples\n",
    "if high_conf_samples:\n",
    "    x_high_conf = pd.concat(high_conf_samples, axis=0)\n",
    "    y_high_conf = np.array(high_conf_labels)\n",
    "else:\n",
    "    x_high_conf = pd.DataFrame()\n",
    "    y_high_conf = np.array([])\n",
    "\n",
    "print(f\"Selected {len(y_high_conf)} high-confidence samples.\")\n",
    "\n",
    "# 4. Combine with your original training data\n",
    "x_train_aug = pd.concat([x_train, x_high_conf], axis=0)\n",
    "y_train_aug = np.concatenate([y_train, y_high_conf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train_aug, y_train_aug,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[f1_callback, cp]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict(x_test)\n",
    "pred = pred_probs.argmax(axis=1)\n",
    "\n",
    "omni_probs = model.predict(x_grouped)\n",
    "omni_pred = omni_probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbdf7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(omni_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43b062",
   "metadata": {},
   "source": [
    "## PCA aumgented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bc3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0606b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('PCA of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b8e88",
   "metadata": {},
   "source": [
    "## UMAP augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_grouped)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=omni_pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of Omni Data Colored by Predicted Class')\n",
    "plt.colorbar(scatter, label='Predicted Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = umap.UMAP()\n",
    "X_pca = pca.fit_transform(x_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pred, alpha=0.7, s=10)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('UMAP of cic data Colored by true labels')\n",
    "plt.colorbar(scatter, label='True labels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661be1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "background = x_train.iloc[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "\n",
    "explainer = shap.Explainer(model, background)\n",
    "shap_values = explainer(x_test[:200])\n",
    "\n",
    "shap.summary_plot(shap_values, x_test[:200], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3584ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importances = np.array(rf.feature_importances_).flatten()\n",
    "shap_vals = shap_values.values  \n",
    "shap_importance = np.abs(shap_vals).mean(axis=0).mean(axis=1)\n",
    "\n",
    "assert len(rf_importances) == len(shap_importance) == x_train.shape[1]\n",
    "\n",
    "# Create the comparison DataFrame\n",
    "compare_df = pd.DataFrame({\n",
    "    'Feature': x_train.columns,\n",
    "    'Random Forest Importance': rf_importances,\n",
    "    'SHAP Importance': shap_importance\n",
    "}).set_index('Feature')\n",
    "\n",
    "# Sort and plot\n",
    "compare_df = compare_df.sort_values('SHAP Importance', ascending=True)\n",
    "\n",
    "compare_df.plot(kind='barh', figsize=(10, 8))\n",
    "plt.title('Feature Importances: Random Forest vs SHAP (NN)')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_vals = silhouette_samples(x_grouped, omni_pred)\n",
    "avg_silhouette = sil_(x_grouped, omni_pred)\n",
    "\n",
    "# Sort for better visualization\n",
    "sorted_idx = np.argsort(omni_pred)\n",
    "sorted_silhouette_vals = silhouette_vals[sorted_idx]\n",
    "sorted_cluster_labels = omni_pred[sorted_idx]\n",
    "\n",
    "# Create silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_lower = 10\n",
    "unique_labels = np.unique(omni_pred)\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_sil_vals = sorted_silhouette_vals[sorted_cluster_labels == label]\n",
    "    label_sil_vals.sort()\n",
    "    y_upper = y_lower + len(label_sil_vals)\n",
    "\n",
    "    color = plt.cm.viridis(float(label) / (len(unique_labels) - 1))\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, label_sil_vals, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    ax.text(-0.05, y_lower + 0.5 * len(label_sil_vals), f'Cluster {label}')\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "# Draw average silhouette score line\n",
    "ax.axvline(avg_silhouette, color=\"red\", linestyle=\"--\", label=f\"Avg Silhouette = {avg_silhouette:.2f}\")\n",
    "ax.set_title(\"Silhouette Plot for HDBSCAN Clusters (Excluding Noise)\")\n",
    "ax.set_xlabel(\"Silhouette Coefficient Values\")\n",
    "ax.set_ylabel(\"Cluster Label\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fccbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = grouped_df.copy()\n",
    "df_analysis['predicted_label'] = omni_pred\n",
    "cmd_cols = [col for col in df_analysis.columns if col.startswith('cmd_')]\n",
    "\n",
    "# Get proportions per class\n",
    "binary_feature_means = df_analysis.groupby('predicted_label')[cmd_cols].mean() *100\n",
    "\n",
    "label_map = {\n",
    "    0: 'BruteForce',\n",
    "    1: 'DoS/DDoS',\n",
    "    2: 'Other',\n",
    "    3: 'Scan',\n",
    "    4: 'WebAttack'\n",
    "}\n",
    "\n",
    "binary_feature_means = binary_feature_means.rename(index=label_map)\n",
    "\n",
    "print(binary_feature_means.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(binary_feature_means, annot=True, cmap=\"Reds\", fmt=\".1f\")\n",
    "plt.title(\"Command Feature Usage (% of samples per predicted class)\")\n",
    "plt.xlabel(\"Command\")\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
